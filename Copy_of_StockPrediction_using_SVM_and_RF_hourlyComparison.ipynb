{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishahmshah1025/Mindspark-24/blob/main/Copy_of_StockPrediction_using_SVM_and_RF_hourlyComparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKRKJXUdmWNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d320e6b-fdb2-41c3-ce51-8d93d88f3e8c"
      },
      "source": [
        "!pip install yfinance\n",
        "!pip install GetOldTweets3\n",
        "!pip install treeinterpreter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.44)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.5)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
            "Collecting GetOldTweets3\n",
            "  Downloading GetOldTweets3-0.0.11-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from GetOldTweets3) (4.9.4)\n",
            "Collecting pyquery>=1.2.10 (from GetOldTweets3)\n",
            "  Downloading pyquery-2.0.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting cssselect>=1.2.0 (from pyquery>=1.2.10->GetOldTweets3)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Downloading GetOldTweets3-0.0.11-py3-none-any.whl (13 kB)\n",
            "Downloading pyquery-2.0.1-py3-none-any.whl (22 kB)\n",
            "Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: cssselect, pyquery, GetOldTweets3\n",
            "Successfully installed GetOldTweets3-0.0.11 cssselect-1.2.0 pyquery-2.0.1\n",
            "Collecting treeinterpreter\n",
            "  Downloading treeinterpreter-0.2.3-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Downloading treeinterpreter-0.2.3-py2.py3-none-any.whl (6.0 kB)\n",
            "Installing collected packages: treeinterpreter\n",
            "Successfully installed treeinterpreter-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2DF0dVzmwmM"
      },
      "source": [
        "import datetime\n",
        "import GetOldTweets3 as got\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import sys\n",
        "import re\n",
        "import string\n",
        "import json\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_sXGERam1DV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301ff086-6044-40ed-9c75-63d694adc5e0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from nltk.sentiment import SentimentAnalyzer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import unicodedata\n",
        "sentiment_i_a = SentimentIntensityAnalyzer()\n",
        "\n",
        "from nltk.corpus import subjectivity\n",
        "from nltk.sentiment.util import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGKnfF23m3rr"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from treeinterpreter import treeinterpreter as ti\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3yLYfHtm9oa"
      },
      "source": [
        "# Get hourly stock data\n",
        "def getHourlyStocks(stockname):\n",
        "  company = yf.Ticker(stockname)\n",
        "  stockdata = company.history(interval=\"60m\")\n",
        "  stockdata.to_csv('stockData_' + stockname +'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PMf1VAUY8DM"
      },
      "source": [
        "# process stock data to get date and time separately\n",
        "def processStockData(stockname):\n",
        "  stockdata = pd.read_csv('stockData_' + stockname +'.csv',encoding='utf-8')\n",
        "  stockdata.head()\n",
        "\n",
        "  temp = str(stockdata['Datetime'].values)\n",
        "  new = temp.split(\"\\n\")\n",
        "  temp1 = ' '.join(str(new).split())\n",
        "  temp1 = temp1.replace('\"', '')\n",
        "  temp1 = temp1.replace('\\'', '')\n",
        "  temp1 = temp1.replace(',', '')\n",
        "  temp1 = temp1.replace('[', '')\n",
        "  temp1 = temp1.replace(']', '')\n",
        "  temp1 = temp1.replace('-04:00', '')\n",
        "  new2 = temp1.split(\" \")\n",
        "  new2 = [x.strip() for x in new2 if x.strip()]\n",
        "\n",
        "  indx = 0\n",
        "  for i in range(0,len(new2),2):\n",
        "    stockdata.at[indx,'date'] = new2[i]\n",
        "    indx = indx + 1\n",
        "\n",
        "  indx = 0\n",
        "  for j in range(1,len(new2),2):\n",
        "    stockdata.at[indx,'time'] = new2[j]\n",
        "    indx = indx + 1\n",
        "\n",
        "  stockdata = stockdata.drop('Datetime', axis= 1)\n",
        "  stockdata['time'] = stockdata['time'].apply(lambda x: datetime.datetime.strptime(x,'%H:%M:%S').time())\n",
        "  stockdata.head()\n",
        "  stockdata.to_csv('processedStockData_' + stockname +'.csv')\n",
        "  startDate = stockdata['date'].iloc[0]\n",
        "  endDate = stockdata['date'].iloc[len(stockdata)-1]\n",
        "  return startDate, endDate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za9kkTJWoBDs"
      },
      "source": [
        "#Method for data cleaning\n",
        "class TweetCleaner:\n",
        "    def __init__(self):\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.punc_table = str.maketrans(\"\", \"\", string.punctuation) # to remove punctuation from each word in tokenize\n",
        "\n",
        "    def compound_word_split(self, compound_word):\n",
        "        matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', compound_word)\n",
        "        return [m.group(0) for m in matches]\n",
        "\n",
        "    def remove_non_ascii_chars(self, text):\n",
        "        return ''.join([w if ord(w) < 128 else ' ' for w in text])\n",
        "\n",
        "    def remove_hyperlinks(self,text):\n",
        "        return ' '.join([w for w in text.split(' ')  if not 'http' in w])\n",
        "\n",
        "    def get_cleaned_text(self, text):\n",
        "        cleaned_tweet = text.replace('\\\"','').replace('\\'','').replace('-',' ')\n",
        "        cleaned_tweet =  self.remove_non_ascii_chars(cleaned_tweet)\n",
        "        if re.match(r'RT @[_A-Za-z0-9]+:',cleaned_tweet):\n",
        "            cleaned_tweet = cleaned_tweet[cleaned_tweet.index(':')+2:]\n",
        "        cleaned_tweet = self.remove_hyperlinks(cleaned_tweet)\n",
        "        cleaned_tweet = cleaned_tweet.replace('#','HASHTAGSYMBOL').replace('@','ATSYMBOL') # to avoid being removed while removing punctuations\n",
        "        tokens = [w.translate(self.punc_table) for w in word_tokenize(cleaned_tweet)] # remove punctuations and tokenize\n",
        "        tokens = [nltk.WordNetLemmatizer().lemmatize(w) for w in tokens if not w.lower() in self.stop_words and len(w)>1] # remove stopwords and single length words\n",
        "        cleaned_tweet = ' '.join(tokens)\n",
        "        cleaned_tweet = cleaned_tweet.replace('HASHTAGSYMBOL','#').replace('ATSYMBOL','@')\n",
        "        cleaned_tweet = cleaned_tweet\n",
        "        return cleaned_tweet\n",
        "\n",
        "    def clean_tweets(self, tweets, is_bytes = False):\n",
        "        test_tweet_list = []\n",
        "        for tweet in tweets:\n",
        "            if is_bytes:\n",
        "                test_tweet_list.append(self.get_cleaned_text(ast.literal_eval(tweet).decode(\"UTF-8\")))\n",
        "            else:\n",
        "                test_tweet_list.append(self.get_cleaned_text(tweet))\n",
        "        return test_tweet_list\n",
        "\n",
        "    def clean_single_tweet(self, tweet, is_bytes = False):\n",
        "        if is_bytes:\n",
        "             return self.get_cleaned_text(ast.literal_eval(tweet).decode(\"UTF-8\"))\n",
        "        return self.get_cleaned_text(tweet)\n",
        "\n",
        "    def cleaned_file_creator(self, op_file_name, value1, value2):\n",
        "        csvFile = open(op_file_name, 'w+')\n",
        "        csvWriter = csv.writer(csvFile)\n",
        "        for tweet in range(len(value1)):\n",
        "            csvWriter.writerow([value1[tweet], value2[tweet]])\n",
        "        csvFile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI38W6S8oR1g"
      },
      "source": [
        "#fetch tweet data\n",
        "def fetchTweets(stockname, startDate, endDate):\n",
        "  csvFile = open('tweets_' + stockname + '.csv', 'a',encoding=\"utf-8\")\n",
        "  csvWriter = csv.writer(csvFile, lineterminator= '\\n')\n",
        "  cleanObj = TweetCleaner()\n",
        "\n",
        "  tweetCriteria = got.manager.TweetCriteria().setQuerySearch(stockname).setSince(startDate).setUntil(endDate).setTopTweets(\"true\")\n",
        "  tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "  try:\n",
        "    for tweet in tweets:\n",
        "      tweet_text = tweet.text.encode('utf-8')\n",
        "      tweet_text = cleanObj.get_cleaned_text(tweet_text.decode())\n",
        "      tweetDate = tweet.date\n",
        "      csvWriter.writerow([tweetDate, tweet.text])\n",
        "  except BaseException as e:\n",
        "      print('failed on_status,',str(e))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQVAESXMoosz"
      },
      "source": [
        "# process tweet data to get date and time separately\n",
        "def processTweetData(stockname):\n",
        "  columns=['Date','Tweets']\n",
        "  tweets = pd.read_csv('tweets_' + stockname + '.csv',encoding='utf-8', names=columns, header=None)\n",
        "\n",
        "  temp = str(tweets['Date'].values)\n",
        "  new = temp.split(\"\\n\")\n",
        "  temp1 = ' '.join(str(new).split())\n",
        "  temp1 = temp1.replace('\"', '')\n",
        "  temp1 = temp1.replace('\\'', '')\n",
        "  temp1 = temp1.replace(',', '')\n",
        "  temp1 = temp1.replace('[', '')\n",
        "  temp1 = temp1.replace(']', '')\n",
        "  temp1 = temp1.replace('+00:00', '')\n",
        "  new2 = temp1.split(\" \")\n",
        "  new2 = [x.strip() for x in new2 if x.strip()]\n",
        "\n",
        "  indx = 0\n",
        "  for i in range(0,len(new2),2):\n",
        "    tweets.at[indx,'date'] = new2[i]\n",
        "    indx = indx + 1\n",
        "\n",
        "  indx = 0\n",
        "  for j in range(1,len(new2),2):\n",
        "    tweets.at[indx,'time'] = new2[j]\n",
        "    indx = indx + 1\n",
        "\n",
        "  tweets = tweets.drop('Date', 1)\n",
        "  tweets.head()\n",
        "  tweets.to_csv('processedTweets_' + stockname + '.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs0qj0hvvAgQ"
      },
      "source": [
        "# process both stock and tweet data to get prices for respective date and time\n",
        "def processData(stockname):\n",
        "  date_time_obj1 = datetime.datetime.strptime('09:30:00', '%H:%M:%S').time()\n",
        "  date_time_obj2 = datetime.datetime.strptime('10:30:00', '%H:%M:%S').time()\n",
        "  date_time_obj3 = datetime.datetime.strptime('11:30:00', '%H:%M:%S').time()\n",
        "  date_time_obj4 = datetime.datetime.strptime('12:30:00', '%H:%M:%S').time()\n",
        "  date_time_obj5 = datetime.datetime.strptime('13:30:00', '%H:%M:%S').time()\n",
        "  date_time_obj6 = datetime.datetime.strptime('14:30:00', '%H:%M:%S').time()\n",
        "  date_time_obj7 = datetime.datetime.strptime('15:30:00', '%H:%M:%S').time()\n",
        "\n",
        "  column_names = [\"date\", \"time\", \"Tweets\"]\n",
        "  df = pd.DataFrame(columns = column_names)\n",
        "\n",
        "  tweets = pd.read_csv('processedTweets_' + stockname + '.csv',encoding='utf-8')\n",
        "  tweets['time'] = tweets['time'].apply(lambda x: datetime.datetime.strptime(x,'%H:%M:%S').time())\n",
        "\n",
        "  readStockData = pd.read_csv('processedStockData_' + stockname +'.csv')\n",
        "\n",
        "  indx1 = 0\n",
        "  indx2 = 1\n",
        "  indx3 = 2\n",
        "  indx4 = 3\n",
        "  indx5 = 4\n",
        "  indx6 = 5\n",
        "\n",
        "  get_tweet1 = \"\"\n",
        "  get_tweet2 = \"\"\n",
        "  get_tweet3 = \"\"\n",
        "  get_tweet4 = \"\"\n",
        "  get_tweet5 = \"\"\n",
        "  get_tweet6 = \"\"\n",
        "\n",
        "  # mapping hourly tweets\n",
        "  for i in range(0,len(tweets)-1):\n",
        "    get_date= tweets.date.iloc[i]\n",
        "    next_date= tweets.date.iloc[i+1]\n",
        "    if(str(get_date)==str(next_date)):\n",
        "      # check time\n",
        "      if tweets.time.iloc[i] > date_time_obj1 and tweets.time.iloc[i] < date_time_obj2:\n",
        "        get_tweet1 = get_tweet1 + tweets.Tweets.iloc[i] + \" \"\n",
        "\n",
        "      if tweets.time.iloc[i] > date_time_obj2 and tweets.time.iloc[i] < date_time_obj3:\n",
        "        get_tweet2 = get_tweet2 + tweets.Tweets.iloc[i] + \" \"\n",
        "\n",
        "      if tweets.time.iloc[i] > date_time_obj3 and tweets.time.iloc[i] < date_time_obj4:\n",
        "        get_tweet3 = get_tweet3 + tweets.Tweets.iloc[i] + \" \"\n",
        "\n",
        "      if tweets.time.iloc[i] > date_time_obj4 and tweets.time.iloc[i] < date_time_obj5:\n",
        "        get_tweet4 = get_tweet4 + tweets.Tweets.iloc[i] + \" \"\n",
        "\n",
        "      if tweets.time.iloc[i] > date_time_obj5 and tweets.time.iloc[i] < date_time_obj6:\n",
        "        get_tweet5 = get_tweet5 + tweets.Tweets.iloc[i] + \" \"\n",
        "\n",
        "      if tweets.time.iloc[i] > date_time_obj6 and tweets.time.iloc[i] < date_time_obj7:\n",
        "        get_tweet6 = get_tweet6 + tweets.Tweets.iloc[i] + \" \"\n",
        "\n",
        "    if(str(get_date)!=str(next_date)):\n",
        "      df.at[indx1,'date'] = get_date\n",
        "      df.at[indx1,'time'] = date_time_obj2\n",
        "      df.at[indx1,'Tweets'] = get_tweet1\n",
        "\n",
        "      df.at[indx2,'date'] = get_date\n",
        "      df.at[indx2,'time'] = date_time_obj3\n",
        "      df.at[indx2,'Tweets'] = get_tweet2\n",
        "\n",
        "      df.at[indx3,'date'] = get_date\n",
        "      df.at[indx3,'time'] = date_time_obj4\n",
        "      df.at[indx3,'Tweets'] = get_tweet3\n",
        "\n",
        "      df.at[indx4,'date'] = get_date\n",
        "      df.at[indx4,'time'] = date_time_obj5\n",
        "      df.at[indx4,'Tweets'] = get_tweet4\n",
        "\n",
        "      df.at[indx5,'date'] = get_date\n",
        "      df.at[indx5,'time'] = date_time_obj6\n",
        "      df.at[indx5,'Tweets'] = get_tweet5\n",
        "\n",
        "      df.at[indx6,'date'] = get_date\n",
        "      df.at[indx6,'time'] = date_time_obj7\n",
        "      df.at[indx6,'Tweets'] = get_tweet6\n",
        "\n",
        "      indx1 = indx1 + 6\n",
        "      indx2 = indx2 + 6\n",
        "      indx3 = indx3 + 6\n",
        "      indx4 = indx4 + 6\n",
        "      indx5 = indx5 + 6\n",
        "      indx6 = indx6 + 6\n",
        "\n",
        "      get_tweet1 = \"\"\n",
        "      get_tweet2 = \"\"\n",
        "      get_tweet3 = \"\"\n",
        "      get_tweet4 = \"\"\n",
        "      get_tweet5 = \"\"\n",
        "      get_tweet6 = \"\"\n",
        "\n",
        "  # drop rows if tweets are not present\n",
        "  df['Tweets'].replace('', np.nan, inplace=True)\n",
        "  df.dropna(subset=['Tweets'], inplace=True)\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "  df.head()\n",
        "\n",
        "  # map prices for respective date and time\n",
        "  df['Prices']=\"\"\n",
        "  for i in range (0,len(df)):\n",
        "    for j in range (0,len(readStockData)):\n",
        "      get_tweet_date = df.date.iloc[i]\n",
        "      get_tweet_time = df.time.iloc[i]\n",
        "\n",
        "      get_stock_date = readStockData.date.iloc[j]\n",
        "      get_stock_time = readStockData.time.iloc[j]\n",
        "\n",
        "      if(str(get_stock_date)==str(get_tweet_date)):\n",
        "        if(str(get_tweet_time) == str(get_stock_time)):\n",
        "          df.at[i,'Prices'] = int(readStockData.Close[j])\n",
        "          break\n",
        "\n",
        "  # dropping rows if prices are not available\n",
        "  df['Prices'].replace('', np.nan, inplace=True)\n",
        "  df.dropna(subset=['Prices'], inplace=True)\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "  df['Prices'] = df['Prices'].apply(np.int64)\n",
        "  df.to_csv('processedData_' + stockname +'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z9KD24fvLuZ"
      },
      "source": [
        "# performing sentiment analysis\n",
        "def sentimentAnalysis(stockname):\n",
        "  df = pd.read_csv('processedData_' + stockname +'.csv')\n",
        "  df[\"Comp\"] = ''\n",
        "  df[\"Negative\"] = ''\n",
        "  df[\"Neutral\"] = ''\n",
        "  df[\"Positive\"] = ''\n",
        "  for indexx, row in df.T.iteritems():\n",
        "    try:\n",
        "      sentence_i = unicodedata.normalize('NFKD', df.loc[indexx, 'Tweets'])\n",
        "      sentence_sentiment = sentiment_i_a.polarity_scores(sentence_i)\n",
        "      df.at[indexx, 'Comp'] =  sentence_sentiment['compound']\n",
        "      df.at[indexx, 'Negative'] = sentence_sentiment['neg']\n",
        "      df.at[indexx, 'Neutral'] =  sentence_sentiment['neu']\n",
        "      df.at[indexx, 'Positive'] = sentence_sentiment['pos']\n",
        "    except TypeError:\n",
        "      print('failed on_status,',str(e))\n",
        "\n",
        "  print(df.head())\n",
        "  df.to_csv('sentimentAnalysis_' + stockname +'.csv')\n",
        "  posi=0\n",
        "  nega=0\n",
        "  neutral = 0\n",
        "  for i in range (0,len(df)):\n",
        "    get_val=df.Comp[i]\n",
        "    if(float(get_val)<(0)):\n",
        "        nega=nega+1\n",
        "    if(float(get_val>(0))):\n",
        "        posi=posi+1\n",
        "    if(float(get_val)==(0)):\n",
        "        neutral=neutral+1\n",
        "\n",
        "  posper=(posi/(len(df)))*100\n",
        "  negper=(nega/(len(df)))*100\n",
        "  neutralper=(neutral/(len(df)))*100\n",
        "\n",
        "  print(\"% of positive tweets= \",posper)\n",
        "  print(\"% of negative tweets= \",negper)\n",
        "  print(\"% of neutral tweets= \",neutralper)\n",
        "\n",
        "  arr=np.asarray([posper,negper,neutralper], dtype=int)\n",
        "  plt.figure()\n",
        "  plt.pie(arr,labels=['positive','negative', 'neutral'])\n",
        "  plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQjF3yOovSKI"
      },
      "source": [
        "# Predicting stock prices using Random Forest model\n",
        "def RandomForestModel(stockname):\n",
        "  df = pd.read_csv('sentimentAnalysis_' + stockname +'.csv')\n",
        "  train, test = train_test_split(df, shuffle=False, test_size=0.2)\n",
        "  print(train.size)\n",
        "  print(test.size)\n",
        "\n",
        "  sentiment_score_list_train = []\n",
        "  for date, row in train.T.iteritems():\n",
        "    sentiment_score = np.asarray([df.loc[date, 'Negative'], df.loc[date, 'Neutral'],  df.loc[date, 'Positive']])\n",
        "    sentiment_score_list_train.append(sentiment_score)\n",
        "  numpy_df_train = np.asarray(sentiment_score_list_train)\n",
        "\n",
        "  sentiment_score_list_test = []\n",
        "  for date, row in test.T.iteritems():\n",
        "    sentiment_score = np.asarray([df.loc[date, 'Negative'], df.loc[date, 'Neutral'], df.loc[date, 'Positive']])\n",
        "    sentiment_score_list_test.append(sentiment_score)\n",
        "  numpy_df_test = np.asarray(sentiment_score_list_test)\n",
        "\n",
        "  y_train = pd.DataFrame(train['Prices'])\n",
        "  y_test = pd.DataFrame(test['Prices'])\n",
        "\n",
        "  rf = RandomForestRegressor()\n",
        "  rf.fit(numpy_df_train, y_train)\n",
        "  prediction, bias, contributions = ti.predict(rf, numpy_df_test)\n",
        "\n",
        "  print(\"\\n\\n\")\n",
        "  plt.figure()\n",
        "  plt.plot(test['Prices'].iloc[:].values)\n",
        "  plt.plot(prediction.flatten())\n",
        "  plt.title('Random Forest predicted prices')\n",
        "  plt.ylabel('Stock Prices')\n",
        "  plt.xlabel('Days')\n",
        "  plt.legend(['actual', 'predicted'])\n",
        "  plt.show()\n",
        "\n",
        "  print(\"\\n\\n\")\n",
        "  print(\"RMSE value for Random Forest Model : \")\n",
        "  rmse = sqrt(mean_squared_error(y_test, prediction.flatten()))\n",
        "  print(rmse)\n",
        "  print(\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1rjsOY6vaNQ"
      },
      "source": [
        "# Predicting stock prices using Support Vector Regression model\n",
        "def SVRModel(stockname):\n",
        "  df = pd.read_csv('sentimentAnalysis_' + stockname +'.csv')\n",
        "  train, test = train_test_split(df, shuffle=False, test_size=0.2)\n",
        "  print(train.size)\n",
        "  print(test.size)\n",
        "\n",
        "  sentiment_score_list_train = []\n",
        "  for date, row in train.T.iteritems():\n",
        "    sentiment_score = np.asarray([df.loc[date, 'Negative'], df.loc[date, 'Neutral'],  df.loc[date, 'Positive']])\n",
        "    sentiment_score_list_train.append(sentiment_score)\n",
        "  numpy_df_train = np.asarray(sentiment_score_list_train)\n",
        "\n",
        "  sentiment_score_list_test = []\n",
        "  for date, row in test.T.iteritems():\n",
        "    sentiment_score = np.asarray([df.loc[date, 'Negative'], df.loc[date, 'Neutral'], df.loc[date, 'Positive']])\n",
        "    sentiment_score_list_test.append(sentiment_score)\n",
        "  numpy_df_test = np.asarray(sentiment_score_list_test)\n",
        "\n",
        "  y_train = pd.DataFrame(train['Prices'])\n",
        "  y_test = pd.DataFrame(test['Prices'])\n",
        "\n",
        "  svr_rbf = SVR(kernel='rbf', C=1e6, gamma=0.1)\n",
        "  svr_rbf.fit(numpy_df_train, y_train.values.flatten())\n",
        "  output_test_svm = svr_rbf.predict(numpy_df_test)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(test['Prices'].iloc[:].values)\n",
        "  plt.plot(output_test_svm)\n",
        "  plt.title('SVM predicted prices')\n",
        "  plt.ylabel('Stock Prices')\n",
        "  plt.xlabel('Days')\n",
        "  plt.legend(['actual', 'predicted'])\n",
        "  plt.show()\n",
        "\n",
        "  print(\"\\n\\n\")\n",
        "  print(\"RMSE value for Support Vector Regression Model : \")\n",
        "  rmse = sqrt(mean_squared_error(y_test, output_test_svm))\n",
        "  print(rmse)\n",
        "  print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ_mXvB1WiUp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07bfe3f3-7298-4316-83fb-794d7e29cbce"
      },
      "source": [
        "def main():\n",
        "  name = input(\"Enter a valid STOCKNAME of the Corporation: \") #enter the name of the company\n",
        "  if(len(name) > 0):\n",
        "    STOCKNAME  = name\n",
        "  else:\n",
        "    STOCKNAME = \"AAPL\"\n",
        "\n",
        "  #Get Stock Details and get date and time\n",
        "  print(\"------------------------------ Getting Stock details and processing it -----------------------------\")\n",
        "  getHourlyStocks(STOCKNAME)\n",
        "  startDate, endDate = processStockData(STOCKNAME)\n",
        "  print(\"Stock Details fetched! \\n\")\n",
        "\n",
        "  #Fetching tweets and get date and time\n",
        "  print(\"------------------------------ Fetching Tweets and processing it-----------------------------\")\n",
        "  fetchTweets(STOCKNAME, startDate, endDate)\n",
        "  processTweetData(STOCKNAME)\n",
        "  print(\"Tweets fetched! \\n\")\n",
        "\n",
        "  # Process data by fetching Tweets and prices for respective date and hour\n",
        "  print(\"------------- Process data by fetching Tweets and prices for respective date and hour ----------------------\")\n",
        "  processData(STOCKNAME)\n",
        "  print(\"Completed Data Processing! \\n\")\n",
        "\n",
        "  # Sentiment analysis of tweets on hourly basis\n",
        "  print(\"------------------------------ Sentiment analysis of tweets on hourly basis-----------------------------\")\n",
        "  sentimentAnalysis(STOCKNAME)\n",
        "  print(\"Completed sentiment Analysis! \\n\")\n",
        "\n",
        "  # Predicting stock prices using Random Forest model\n",
        "  print(\"------------------------------ Predicting stock prices using Random Forest model-----------------------------\")\n",
        "  RandomForestModel(STOCKNAME)\n",
        "  print(\"Completed Random Forest prediction! \\n\")\n",
        "\n",
        "  # Predicting stock prices using Support Vector Regression model\n",
        "  print(\"------------------------------ Predicting stock prices using Support Vector Regression model-----------------------------\")\n",
        "  SVRModel(STOCKNAME)\n",
        "  print(\"Completed Support Vector Regression prediction! \\n\")\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a valid STOCKNAME of the Corporation: \n",
            "------------------------------ Getting Stock details and processing it -----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Details fetched! \n",
            "\n",
            "------------------------------ Fetching Tweets and processing it-----------------------------\n",
            "An error occured during an HTTP request: HTTP Error 403: Forbidden\n",
            "Try to open in browser: https://twitter.com/search?q=AAPL%20since%3A2024-09-18%20until%3A2024-10-17&src=typd\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/GetOldTweets3/manager/TweetManager.py\", line 343, in getJsonResponse\n",
            "    response = opener.open(url)\n",
            "  File \"/usr/lib/python3.10/urllib/request.py\", line 525, in open\n",
            "    response = meth(req, response)\n",
            "  File \"/usr/lib/python3.10/urllib/request.py\", line 634, in http_response\n",
            "    response = self.parent.error(\n",
            "  File \"/usr/lib/python3.10/urllib/request.py\", line 563, in error\n",
            "    return self._call_chain(*args)\n",
            "  File \"/usr/lib/python3.10/urllib/request.py\", line 496, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/usr/lib/python3.10/urllib/request.py\", line 643, in http_error_default\n",
            "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
            "urllib.error.HTTPError: HTTP Error 403: Forbidden\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-17-366c9dfaa7cb>\", line 40, in <cell line: 40>\n",
            "    main()\n",
            "  File \"<ipython-input-17-366c9dfaa7cb>\", line 16, in main\n",
            "    fetchTweets(STOCKNAME, startDate, endDate)\n",
            "  File \"<ipython-input-8-b83b1e61b3fd>\", line 8, in fetchTweets\n",
            "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/GetOldTweets3/manager/TweetManager.py\", line 65, in getTweets\n",
            "    json = TweetManager.getJsonResponse(tweetCriteria, refreshCursor, cookieJar, proxy, user_agent, debug=debug)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/GetOldTweets3/manager/TweetManager.py\", line 348, in getJsonResponse\n",
            "    sys.exit()\n",
            "SystemExit\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/GetOldTweets3/manager/TweetManager.py\u001b[0m in \u001b[0;36mgetJsonResponse\u001b[0;34m(tweetCriteria, refreshCursor, cookieJar, proxy, useragent, debug)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0mjsonResponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-366c9dfaa7cb>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-366c9dfaa7cb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------------------------ Fetching Tweets and processing it-----------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mfetchTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOCKNAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartDate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mprocessTweetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOCKNAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-b83b1e61b3fd>\u001b[0m in \u001b[0;36mfetchTweets\u001b[0;34m(stockname, startDate, endDate)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mtweetCriteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTweetCriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetQuerySearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstockname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetSince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetUntil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetTopTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTweetManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweetCriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/GetOldTweets3/manager/TweetManager.py\u001b[0m in \u001b[0;36mgetTweets\u001b[0;34m(tweetCriteria, receiveBuffer, bufferLength, proxy, debug)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mactive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetJsonResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweetCriteria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefreshCursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcookieJar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'items_html'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/GetOldTweets3/manager/TweetManager.py\u001b[0m in \u001b[0;36mgetJsonResponse\u001b[0;34m(tweetCriteria, refreshCursor, cookieJar, proxy, useragent, debug)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Try to open in browser: https://twitter.com/search?q=%s&src=typd\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlGetData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SL2wDy9cqoy"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}