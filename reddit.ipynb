{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-10-18T18:33:41.747993Z","iopub.execute_input":"2024-10-18T18:33:41.748343Z","iopub.status.idle":"2024-10-18T18:33:43.057369Z","shell.execute_reply.started":"2024-10-18T18:33:41.748305Z","shell.execute_reply":"2024-10-18T18:33:43.056335Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"pip install praw torch transformers vaderSentiment\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T18:33:43.059686Z","iopub.execute_input":"2024-10-18T18:33:43.060303Z","iopub.status.idle":"2024-10-18T18:33:58.557746Z","shell.execute_reply.started":"2024-10-18T18:33:43.060233Z","shell.execute_reply":"2024-10-18T18:33:58.556540Z"}},"outputs":[{"name":"stdout","text":"Collecting praw\n  Downloading praw-7.7.1-py3-none-any.whl.metadata (9.8 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nCollecting vaderSentiment\n  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\nCollecting prawcore<3,>=2.1 (from praw)\n  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: update-checker>=0.18 in /opt/conda/lib/python3.10/site-packages (from praw) (0.18.0)\nRequirement already satisfied: websocket-client>=0.54.0 in /opt/conda/lib/python3.10/site-packages (from praw) (1.8.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading praw-7.7.1-py3-none-any.whl (191 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.0/191.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\nInstalling collected packages: vaderSentiment, prawcore, praw\nSuccessfully installed praw-7.7.1 prawcore-2.4.0 vaderSentiment-3.3.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import praw\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n\n# Initialize Reddit API (PRAW)\nreddit = praw.Reddit(\n    client_id='t2bNyMB4wU0yXdeWb7nVcQ',\n    client_secret='Y5iOhI76laXgItwsSFTiKfDcRNyqwQ',\n    user_agent='QuantumCoders/0.1 by Ok_profession1025'\n)\n\n# Load FinBERT model and tokenizer\nfinbert_tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\nfinbert_model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone')\n\n# Initialize VADER Sentiment Analyzer\nvader_analyzer = SentimentIntensityAnalyzer()\n\ndef analyze_sentiment_finbert(text):\n    \"\"\"Analyze sentiment using FinBERT.\"\"\"\n    inputs = finbert_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n    outputs = finbert_model(**inputs)\n    logits = outputs.logits\n    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n    sentiment_scores = probabilities.detach().cpu().numpy()[0]  # Extracting scores\n\n    # FinBERT labels: [0] Negative, [1] Neutral, [2] Positive\n    sentiment_dict = {\n        \"negative\": sentiment_scores[0],\n        \"neutral\": sentiment_scores[1],\n        \"positive\": sentiment_scores[2]\n    }\n    \n    return sentiment_dict\n\ndef analyze_sentiment_vader(text):\n    \"\"\"Analyze sentiment using VADER.\"\"\"\n    sentiment_score = vader_analyzer.polarity_scores(text)\n    sentiment_dict = {\n        \"negative\": sentiment_score['neg'],\n        \"neutral\": sentiment_score['neu'],\n        \"positive\": sentiment_score['pos']\n    }\n    return sentiment_dict\n\ndef get_sentiment(stock_name):\n    \"\"\"Fetch posts from Reddit and analyze sentiment for a specific stock.\"\"\"\n    # Aggregated sentiment results\n    aggregated_sentiments = {\"positive\": 0, \"negative\": 0, \"neutral\": 0}\n    total_posts = 0\n\n    # Fetch posts from multiple subreddits\n    subreddits = ['IndianStockMarket', 'wallstreetbets', 'investing', 'IndianStreetBets']\n    \n    for subreddit in subreddits:\n        posts = reddit.subreddit(subreddit).search(stock_name, limit=100)\n        \n        for post in posts:\n            text = post.title + \" \" + post.selftext\n\n            # Filter out short or low-relevance posts\n            if len(text.split()) < 20:\n                continue\n\n            # Use VADER for general sentiment\n            vader_sentiment = analyze_sentiment_vader(text)\n\n            # Use FinBERT for financial sentiment analysis\n            finbert_sentiment = analyze_sentiment_finbert(text)\n\n            # Combine FinBERT and VADER results by averaging them\n            aggregated_sentiments[\"positive\"] += (vader_sentiment[\"positive\"] + finbert_sentiment[\"positive\"]) / 2\n            aggregated_sentiments[\"negative\"] += (vader_sentiment[\"negative\"] + finbert_sentiment[\"negative\"]) / 2\n            aggregated_sentiments[\"neutral\"] += (vader_sentiment[\"neutral\"] + finbert_sentiment[\"neutral\"]) / 2\n\n            total_posts += 1\n\n    if total_posts > 0:\n        # Normalize sentiment scores by the number of posts processed\n        aggregated_sentiments = {k: v / total_posts for k, v in aggregated_sentiments.items()}\n\n    return aggregated_sentiments\n\nif __name__ == \"__main__\":\n    stock_name = input(\"Enter the stock name: \")\n    sentiment_scores = get_sentiment(stock_name)\n    print(f\"Sentiment Scores for {stock_name}:\")\n    print(f\"Positive: {round(sentiment_scores['positive'], 4)}\")\n    print(f\"Negative: {round(sentiment_scores['negative'], 4)}\")\n    print(f\"Neutral: {round(sentiment_scores['neutral'], 4)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T18:33:58.559746Z","iopub.execute_input":"2024-10-18T18:33:58.560371Z","iopub.status.idle":"2024-10-18T18:34:56.284175Z","shell.execute_reply.started":"2024-10-18T18:33:58.560318Z","shell.execute_reply":"2024-10-18T18:34:56.282900Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba8bd7aeec2a41b781d40e9c4e0fa4c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38d93b6c982e4cf5b47038e4db263d75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab45228d2e284b278818b3488cac0800"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"Enter the stock name:  Tata Motor\n"},{"name":"stdout","text":"Sentiment Scores for Tata Motor:\nPositive: 0.106\nNegative: 0.3726\nNeutral: 0.5215\n","output_type":"stream"}],"execution_count":3}]}