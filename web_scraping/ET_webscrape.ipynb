{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPv23Y+VTfGuKbzQMKNhXMb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishahmshah1025/Mindspark-24/blob/main/ET_webscrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWEE6G8Dyldc",
        "outputId": "9a7a71f3-a196-4838-c67b-35078d217d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.44)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.5)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.6)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 nltk yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import nltk"
      ],
      "metadata": {
        "id": "eDMUseGfysxR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1_eklWcznkV",
        "outputId": "9ab372b2-4d4c-4749-ceca-2234dfa5bd62"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_news_articles(keyword):\n",
        "    # URL for the Economic Times news page\n",
        "    url = \"https://economictimes.indiatimes.com/news\"\n",
        "\n",
        "    # Send a request to fetch the page\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    articles = []\n",
        "\n",
        "    # Find all relevant news items\n",
        "    for item in soup.find_all('article', class_='newslist'):\n",
        "        title_tag = item.find('a')  # 'a' tag contains the link and title\n",
        "        if title_tag:\n",
        "            title = title_tag.text.strip()\n",
        "            link = title_tag['href']\n",
        "\n",
        "            # Check if the keyword is in the headline\n",
        "            if keyword.lower() in title.lower():\n",
        "                article_url = f\"https://economictimes.indiatimes.com{link}\" if link else ''\n",
        "\n",
        "                # Fetch the article summary\n",
        "                summary = fetch_article_summary(article_url)\n",
        "\n",
        "                if summary:  # Only add articles with a summary\n",
        "                    articles.append((title, summary, article_url))\n",
        "\n",
        "    return articles"
      ],
      "metadata": {
        "id": "UtuIET7w1NXb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_article_summary(article_url):\n",
        "    try:\n",
        "        # Request the individual article page\n",
        "        response = requests.get(article_url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find the summary on the article page\n",
        "        summary_tag = soup.find('h2', class_='summary')  # Adjust this if necessary\n",
        "        if summary_tag:\n",
        "            return summary_tag.text.strip()\n",
        "        else:\n",
        "            return \"Summary not available.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching article summary: {e}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "aOvXEkAQHuLr"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    keyword = \"Torrent Pharma\"  # Replace with your desired keyword\n",
        "    news_articles = fetch_news_articles(keyword)\n",
        "\n",
        "    # Print the fetched articles\n",
        "    if news_articles:\n",
        "        for title, summary, url in news_articles:\n",
        "            print(f\"Title: {title}\\nSummary: {summary}\\nURL: {url}\\n\")\n",
        "    else:\n",
        "        print(\"No articles found with that keyword.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7_cOVzTH011",
        "outputId": "45f96e32-3c52-4ab0-a297-eb5cb5dadf64"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Torrent Pharma gets demand notice of Rs 6.32 lakh from NPPA\n",
            "Summary: Torrent Pharmaceuticals has received a demand notice from the National Pharmaceutical Pricing Authority (NPPA) amounting to Rs 6.32 lakh. This penalty pertains to the launch of a new drug for which price approval was sought post-launch. The financial impact on Torrent Pharmaceuticals is stated as non-material.\n",
            "URL: https://economictimes.indiatimes.com/industry/healthcare/biotech/pharmaceuticals/torrent-pharma-gets-demand-notice-of-rs-6-32-lakh-from-nppa/articleshow/114353616.cms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_economy_news_articles(keyword):\n",
        "    # URL for the Economic Times economy news page\n",
        "    url = \"https://economictimes.indiatimes.com/news/economy\"\n",
        "\n",
        "    # Send a request to fetch the page\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    articles = []\n",
        "\n",
        "    # Find all relevant news items\n",
        "    for item in soup.find_all('div', class_='top-news'):\n",
        "        for li in item.find_all('li'):\n",
        "            title_tag = li.find('a')  # 'a' tag contains the link and title\n",
        "            if title_tag:\n",
        "                title = title_tag.text.strip()\n",
        "                link = title_tag['href']\n",
        "\n",
        "                # Check if the keyword is in the headline\n",
        "                if keyword.lower() in title.lower():\n",
        "                    article_url = f\"https://economictimes.indiatimes.com{link}\" if link else ''\n",
        "\n",
        "                    # Fetch the article summary\n",
        "                    summary = fetch_economy_article_summary(article_url)\n",
        "\n",
        "                    if summary:  # Only add articles with a summary\n",
        "                        articles.append((title, summary, article_url))\n",
        "\n",
        "    return articles"
      ],
      "metadata": {
        "id": "Wv84sJ09Gpfk"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_economy_article_summary(article_url):\n",
        "    try:\n",
        "        # Request the individual article page\n",
        "        response = requests.get(article_url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find the summary on the article page\n",
        "        summary_tag = soup.find('h2', class_='summary')  # Adjust this if necessary\n",
        "        if summary_tag:\n",
        "            return summary_tag.text.strip()\n",
        "        else:\n",
        "            return \"Summary not available.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching article summary: {e}\")\n",
        "        return \"\"\n"
      ],
      "metadata": {
        "id": "gqBXUNBSGuat"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    keyword = \"rate cut\"  # Replace with your desired keyword\n",
        "    economy_news_articles = fetch_economy_news_articles(keyword)\n",
        "\n",
        "    # Print the fetched articles\n",
        "    if economy_news_articles:\n",
        "        for title, summary, url in economy_news_articles:\n",
        "            print(f\"Title: {title}\\nSummary: {summary}\\nURL: {url}\\n\")\n",
        "    else:\n",
        "        print(\"No articles found with that keyword.\")"
      ],
      "metadata": {
        "id": "SikHM_3l5w8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6fae32-ee37-49c4-8227-8bcba8177a90"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Rate cut 'risky, premature' as growth remains steady, says RBI's Shaktikanta Das\n",
            "Summary: RBI's governor Shaktikanta Das during India Credit Forum hosted by Bloomberg said cutting interest rates in coming Monetary Policy Committee meeting scheduled for December would be 'risky and premature' as country's grouwth remains steady with inflation moderating.\n",
            "URL: https://economictimes.indiatimes.com/news/economy/policy/rate-cut-risky-premature-as-growth-remains-steady-inflation-moderating-rbis-shaktikanta-das/articleshow/114349138.cms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZ1GJ0qCJC5E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}